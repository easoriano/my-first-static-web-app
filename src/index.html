<!--<!DOCTYPE html>
    <html>
        <head>
          <title>My Page</title>
            </head>
                <body>
                     <h1>My Diabeties</h1>
                        
                
                        <script type = "text/javascript" src="web.js"></script>
         
                        <p>Click the following button to see the function in action</p>  
                        <button type = "button1" onclick = "diabeties()" value = "Display">  
 
        </body>  
</html>-->
<!--"----------------------------------------------------------------------------------------------- "-->
<!--<html>
  <head>
    <title>My App</title>
  </head>
  <body>
    <h1>Output</h1>
    <p>PatientID: {{ output.PatientID }}</p>
    <p>DiabetesPrediction: {{ output.DiabetesPrediction }}</p>
    <p>Probability: {{ output.Probability }}</p>
  </body>
</html>-->
<!--"----------------------------------------------------------------------------------------------- "-->
<!--<!DOCTYPE html>
<html>
  <head>
    <title>Invoke Azure ML Service</title>
  </head>
  <body>
      <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
<script defer src="https://pyscript.net/latest/pyscript.js"></script>
    <py-script>
      import urllib.request
import json
import os
import ssl

def allowSelfSignedHttps(allowed):
    # bypass the server certificate verification on client side
    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):
        ssl._create_default_https_context = ssl._create_unverified_context

allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.

# set up a proxy handler
proxy_handler = urllib.request.ProxyHandler({'http': 'http://20.252.33.64:80',
                                              'https': 'https://ambitious-water-0d40d801e.2.azurestaticapps.net:37'})
# replace <proxy_host> and <proxy_port> with your proxy server host and port

# create an opener with the proxy handler
opener = urllib.request.build_opener(proxy_handler)

# install the opener as the default opener for all urllib requests
urllib.request.install_opener(opener)

# Request data goes here
# The example below assumes JSON formatting which may be updated
# depending on the format your endpoint expects.
# More information can be found here:
# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script
data =  {
  "Inputs": {
    "input1": [
      {
        "PatientID": 1882185,
        "Pregnancies": 9,
        "PlasmaGlucose": 104,
        "DiastolicBloodPressure": 51,
        "TricepsThickness": 7,
        "SerumInsulin": 24,
        "BMI": 27.36983156,
        "DiabetesPedigree": 1.3504720469999998,
        "Age": 43
      },
      {
        "PatientID": 1662484,
        "Pregnancies": 6,
        "PlasmaGlucose": 73,
        "DiastolicBloodPressure": 61,
        "TricepsThickness": 35,
        "SerumInsulin": 24,
        "BMI": 18.74367404,
        "DiabetesPedigree": 1.074147566,
        "Age": 75
      },
      {
        "PatientID": 1228510,
        "Pregnancies": 4,
        "PlasmaGlucose": 115,
        "DiastolicBloodPressure": 50,
        "TricepsThickness": 29,
        "SerumInsulin": 243,
        "BMI": 34.69215364,
        "DiabetesPedigree": 0.7411599259999999,
        "Age": 59
      }
    ]
  },
  "GlobalParameters": {}
}

body = str.encode(json.dumps(data))

url = 'http://20.252.33.64:80/api/v1/service/predict-diabetes/score'
url = 'https://ambitious-water-0d40d801e.2.azurestaticapps.net/1/api/v1/service/predict-diabetes/score'
# Replace this with the primary/secondary key or AMLToken for the endpoint
api_key = 'crDbBjiIZb2mgOGcJQnT7BPFsR5R64QZ'
if not api_key:
    raise Exception("A key should be provided to invoke the endpoint")

headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}

req = urllib.request.Request(url, body, headers)

try:
    response = urllib.request.urlopen(req)

    result = response.read()
    print(result)
except urllib.error.HTTPError as error:
    print("The request failed with status code: " + str(error.code))

    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure
    print(error.info())

    </py-script>
  </body>
</html>-->

<!--"----------------------------------------------------------------------------------------------- "-->
<!--<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>My HTML Page</title>
  </head>
  <body>
    <h1>My Diabetes Results</h1>
    <div id="results"></div>
      <button onclick="getDiabetesResults()">Get Results</button>
<script src="web.js">
</script>
  </body>
</html>-->
<!--"----------------------------------------------------------------------------------------------- "-->

<!-- <!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Invoke Azure ML Service</title>
  </head>
  <body>
      <h1>My Diabetes Results</h1>
      
    <div id="data"></div>
    <script>
        const url = 'https://projectapiforweb.azure-api.net/v1/api/v1/service/aks-new-diabetes-prediction/score';
       const api_key = 'nxaBjsB5MIUT4BP1EvrC3HmewZkp5AUp'; // Replace this with the primary/secondary key or AMLToken for the endpoint
      if (!api_key) {
        throw new Error("A key should be provided to invoke the endpoint");
      }

      const data = {
        "Inputs": {
          "input1": [
            {
              "PatientID": 1882185,
              "Pregnancies": 9,
              "PlasmaGlucose": 104,
              "DiastolicBloodPressure": 51,
              "TricepsThickness": 7,
              "SerumInsulin": 24,
              "BMI": 27.36983156,
              "DiabetesPedigree": 1.3504720469999998,
              "Age": 43,
              "Diabetic": 0
            }
          ]
        },
        "GlobalParameters": {}
      };
      const options = {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': 'Bearer ' + api_key
        },
        body: JSON.stringify(data)
      };
      fetch(url, options)
        .then(response => response.json())
        .then(data => console.log(data))
        .catch(error => console.error(error));
    </script>
  </body>
</html>
 -->


<!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Invoke Azure ML Service</title>
  </head>
  <body>
      <h1>OpenAI Text DaVinci 002</h1>
      <input type="text" id="textInput" name="textInput">
      <br>
      <button type="button" onclick="generateResponse()">Generate Response</button>
      <p id="textResponse"></p>
      <br>
    
      <div id="data"></div>
    <script>

//const fetch = require('node-fetch'); // Import the fetch module

const OPENAI_API_BASE = "https://senior-project-azure-openai.openai.azure.com/";
const OPENAI_API_VERSION = "2022-12-01";
const OPENAI_API_KEY = "97d86c068132451ea9e014b65258c0d0";

async function generateResponse() {
    const textInput = document.getElementById("textInput").value;

  const response = await fetch(`https://senior-project-azure-openai.openai.azure.com/openai/deployments/text_davinci/completions?api-version=2022-12-01`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'api-key': OPENAI_API_KEY
      
    },
    body: JSON.stringify({
  "prompt": textInput ,
  "temperature": 1,
  "top_p": 0.5,
  "frequency_penalty": 0,
  "presence_penalty": 0,
  "max_tokens": 100,
  "best_of": 1,
  "stop": null
})
  });

  const data = await response.json();
  responsetext=data.choices[0].text;
  const paragraph = document.getElementById("textResponse");
  paragraph.textContent = responsetext;
}
    </script>
  </body>
</html>
